{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "COMPLETION_MODEL = \"gpt-35-turbo\"\n",
    "\n",
    "\n",
    "# 1. role 这个字段一共有三个角色可以选择，其中 system 代表系统，user 代表用户，而 assistant 则代表 AI 的回答。\n",
    "# 2. 当 role 是 system 的时候，content 里面的内容代表我们给 AI 的一个指令，也就是告诉 AI 应该怎么回答用户的问题。\n",
    "#   比如我们希望 AI 都通过中文回答，我们就可以在 content 里面写“你是一个只会用中文回答问题的助理”，这样即使用户问的问题都是英文的，AI 的回复也都会是中文的。\n",
    "# 3. 当 role 是 user 或者 assistant 的时候，content 里面的内容就代表用户和 AI 对话的内容。\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=COMPLETION_MODEL,\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?, 用中文回答\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=COMPLETION_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure Cognitive Services support this too?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "ENGINE = \"gpt-35-turbo\"\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                engine=ENGINE,\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3] # Remove the first round conversation left.\n",
    "        return message"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "conv1 = Conversation(prompt, 2)\n",
    "question1 = \"你是谁？\"\n",
    "print(\"User : %s\" % question1)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question1))\n",
    "\n",
    "question2 = \"请问鱼香肉丝怎么做？\"\n",
    "print(\"User : %s\" % question2)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question2))\n",
    "\n",
    "question3 = \"那蚝油牛肉呢？\"\n",
    "print(\"User : %s\" % question3)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "question4 = \"我问你的第一个问题是什么？\"\n",
    "print(\"User : %s\" % question4)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question4))\n",
    "\n",
    "\n",
    "question5 = \"我问你的第一个问题是什么？\"\n",
    "print(\"User : %s\" % question5)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 计算 Token 数量\n",
    "\n",
    "1. 调用chatgpt的ChatCompletion接口时，返回的response中，包含了token数量\n",
    "2. 可以通过 Tiktoken 库计算 Token 数量，使用不同的 GPT 模型，对应着不同的 Tiktoken 的编码器模型，ChatGPT，采用的是 cl100k_base 的编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import os\n",
    "#\n",
    "# openai.api_type = \"azure\"\n",
    "# openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# openai.api_version = \"2023-05-15\"\n",
    "# openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "#\n",
    "# ENGINE = \"gpt-35-turbo\"\n",
    "\n",
    "\n",
    "class Conversation2:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append( {\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                engine=ENGINE,\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        num_of_tokens = response['usage']['total_tokens']\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3]\n",
    "        return message, num_of_tokens\n",
    "\n",
    "\n",
    "conv2 = Conversation2(prompt, 3)\n",
    "questions = [question1, question2, question3, question4, question5]\n",
    "for question in questions:\n",
    "    answer, num_of_tokens = conv2.ask(question)\n",
    "    print(\"询问 {%s} 消耗的token数量是 : %d\" % (question, num_of_tokens))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "conv2 = Conversation2(prompt, 3)\n",
    "question1 = \"你是谁？\"\n",
    "answer1, num_of_tokens = conv2.ask(question1)\n",
    "print(\"总共消耗的token数量是 : %d\" % (num_of_tokens))\n",
    "\n",
    "prompt_count = len(encoding.encode(prompt))\n",
    "question1_count = len(encoding.encode(question1))\n",
    "answer1_count = len(encoding.encode(answer1))\n",
    "total_count = prompt_count + question1_count + answer1_count\n",
    "print(\"Prompt消耗 %d Token, 问题消耗 %d Token，回答消耗 %d Token，总共消耗 %d Token\" % (prompt_count, question1_count, answer1_count, total_count))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 创建一个聊天机器人"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import gradio as gr\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "\n",
    "conv = Conversation(prompt, 10)\n",
    "\n",
    "def answer(question, history=[]):\n",
    "    history.append(question)\n",
    "    response = conv.ask(question)\n",
    "    history.append(response)\n",
    "    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n",
    "    return responses, history\n",
    "\n",
    "with gr.Blocks(css=\"#chatbot{height:300px} .overflow-y-auto{height:500px}\") as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "\n",
    "    txt.submit(answer, [txt, state], [chatbot, state])\n",
    "\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
